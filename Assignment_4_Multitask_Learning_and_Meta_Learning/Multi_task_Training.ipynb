{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Multi_task_Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "408feb192a934ca5b3156794eacd8ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_82849cfd80b34cfd8838ffe70d3a4809",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f2795e8c7e2947ea86a8ea895555c79b",
              "IPY_MODEL_16a8970e62854d1bb812a9a452342245"
            ]
          }
        },
        "82849cfd80b34cfd8838ffe70d3a4809": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2795e8c7e2947ea86a8ea895555c79b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c5f9f869d2424ec68a707d7a804ca007",
            "_dom_classes": [],
            "description": "Epoch: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25d07157b20247dc9146e38f7c834452"
          }
        },
        "16a8970e62854d1bb812a9a452342245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f74240ffa38d41c88125b55a41103638",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [1:03:49&lt;00:00, 1276.43s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_226d612a1e1640eca87240ef892f41c3"
          }
        },
        "c5f9f869d2424ec68a707d7a804ca007": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "25d07157b20247dc9146e38f7c834452": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f74240ffa38d41c88125b55a41103638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "226d612a1e1640eca87240ef892f41c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c51176cb245b4040a5986970576a1f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4e32b0b6cbfc402ca899438780059715",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c0023455d0884d08bf6e1ef05c780d3c",
              "IPY_MODEL_6c3a5cbdb0e44875ae00cb7476a5937e"
            ]
          }
        },
        "4e32b0b6cbfc402ca899438780059715": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c0023455d0884d08bf6e1ef05c780d3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_103b623c4971417ebb6f691d12258114",
            "_dom_classes": [],
            "description": "Iteration: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2249,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2249,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd42204c6b594236981bd17435db2b64"
          }
        },
        "6c3a5cbdb0e44875ae00cb7476a5937e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_340d2c7f2ad44332b1ca8d8c9f7e55c2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2249/2249 [21:11&lt;00:00,  1.77it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_36c09a41c90d4836b0e4a3556bca0873"
          }
        },
        "103b623c4971417ebb6f691d12258114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd42204c6b594236981bd17435db2b64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "340d2c7f2ad44332b1ca8d8c9f7e55c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "36c09a41c90d4836b0e4a3556bca0873": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a6d2586ff27c4113b927a475c5476247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_935b6da3a13a42f7900c3c81f275379d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_10120c83fc7e4f57892e615697e76a62",
              "IPY_MODEL_4398ecc5150947a9888bfa6a686bdd52"
            ]
          }
        },
        "935b6da3a13a42f7900c3c81f275379d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10120c83fc7e4f57892e615697e76a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4f72f49bfd5040bf92ce763f4ebb2660",
            "_dom_classes": [],
            "description": "Iteration: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2249,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2249,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9bbf8ee8f704020a355382e19739d26"
          }
        },
        "4398ecc5150947a9888bfa6a686bdd52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_714b16ed040b46ceb50c25f80eb415d7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2249/2249 [21:20&lt;00:00,  1.76it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8987b636d706476d9219fcfc1c510d6c"
          }
        },
        "4f72f49bfd5040bf92ce763f4ebb2660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9bbf8ee8f704020a355382e19739d26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "714b16ed040b46ceb50c25f80eb415d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8987b636d706476d9219fcfc1c510d6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aebee5c0bc4e4a2bbb816d49baa23d21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d5d57ed10d984ee99fd13f8f8c473106",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ccfd7cba354749e1afd7abca9abda423",
              "IPY_MODEL_967d47cdb14a4b98921b79189c803535"
            ]
          }
        },
        "d5d57ed10d984ee99fd13f8f8c473106": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ccfd7cba354749e1afd7abca9abda423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b7fc9a60e7b84ce59584f317dd37f35b",
            "_dom_classes": [],
            "description": "Iteration: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2249,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2249,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_abeb9e247eac423197f2adf4bc4a93d9"
          }
        },
        "967d47cdb14a4b98921b79189c803535": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_242fbc40994a40c99ec31a518e7acb2b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2249/2249 [21:18&lt;00:00,  1.76it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38fef6b698854ccbb06975272a63acaa"
          }
        },
        "b7fc9a60e7b84ce59584f317dd37f35b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "abeb9e247eac423197f2adf4bc4a93d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "242fbc40994a40c99ec31a518e7acb2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38fef6b698854ccbb06975272a63acaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98dee5ab22b6444e957fba46fa955775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3b904ff21eb54b10b06892792a9a728c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6b5f0f5ddfa044a9bf3e3690683b2e8a",
              "IPY_MODEL_2ccd3fcc896547cb8c0701fe89bd3229"
            ]
          }
        },
        "3b904ff21eb54b10b06892792a9a728c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6b5f0f5ddfa044a9bf3e3690683b2e8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_171781e7a75245959159d1edf6791239",
            "_dom_classes": [],
            "description": "Validation: rte: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 35,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 35,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_762caf8d863d496d8a079d24ee9fbc4f"
          }
        },
        "2ccd3fcc896547cb8c0701fe89bd3229": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1a457294496e470a833d46121c4a59f9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 35/35 [00:14&lt;00:00,  2.37it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c7f657855c36467db03502b74f939170"
          }
        },
        "171781e7a75245959159d1edf6791239": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "762caf8d863d496d8a079d24ee9fbc4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a457294496e470a833d46121c4a59f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c7f657855c36467db03502b74f939170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c66495eb316244d4830a01144f4c4c08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_28047a01ac0845efb1273f6ee5224a55",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b13aef38574f4421a69b726403429606",
              "IPY_MODEL_1b00746401fa4a589fd30bccd65b9db7"
            ]
          }
        },
        "28047a01ac0845efb1273f6ee5224a55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b13aef38574f4421a69b726403429606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_15740bba74994996a0acb477d69e4f56",
            "_dom_classes": [],
            "description": "Validation: stsb: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 188,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 188,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_84161a10c67845d59230412237990852"
          }
        },
        "1b00746401fa4a589fd30bccd65b9db7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_91bf2ea28d594836a6deedf67f2b93f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 188/188 [00:11&lt;00:00, 16.15it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c6378be1a2df44399f337d30f1b69c54"
          }
        },
        "15740bba74994996a0acb477d69e4f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "84161a10c67845d59230412237990852": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91bf2ea28d594836a6deedf67f2b93f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c6378be1a2df44399f337d30f1b69c54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ebec1bcde124839b1909627c25ce808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c70475cd0a6a4720be9e4daf2244a839",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_35e1c8f514034fbfbdf96a00cd1e6a35",
              "IPY_MODEL_82c0a3ff451248d29464276b391e3ee6"
            ]
          }
        },
        "c70475cd0a6a4720be9e4daf2244a839": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35e1c8f514034fbfbdf96a00cd1e6a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_37ff88b825594d9fb9f38ab70328df59",
            "_dom_classes": [],
            "description": "Validation: commonsense_qa: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 153,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 153,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae2556cc14794d19bdd00d3373f19791"
          }
        },
        "82c0a3ff451248d29464276b391e3ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_163b8f5f7ae245ba9b10a4c2cfbe034b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 153/153 [00:41&lt;00:00,  3.65it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d2bd8364efe476992b2c274dbb00da6"
          }
        },
        "37ff88b825594d9fb9f38ab70328df59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae2556cc14794d19bdd00d3373f19791": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "163b8f5f7ae245ba9b10a4c2cfbe034b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d2bd8364efe476992b2c274dbb00da6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9022705ae74e4b8ab3c9b2a43211817b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ca37cb2bec294cf1bcf88fbec529e52d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a8dc954adfcb4cfd86c70836d6435d45",
              "IPY_MODEL_1da42958a52b495ca24d8ae491751411"
            ]
          }
        },
        "ca37cb2bec294cf1bcf88fbec529e52d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a8dc954adfcb4cfd86c70836d6435d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_702f7ed64e874a4687f773c62dbbd8e5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4151,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4151,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5548ef20ba5e4651bb2965fce3916db0"
          }
        },
        "1da42958a52b495ca24d8ae491751411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9a96d8f2da6f4ffa93d2e03757051e1d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.15k/4.15k [00:01&lt;00:00, 3.70kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25e8225135f244f09308125a407c5bac"
          }
        },
        "702f7ed64e874a4687f773c62dbbd8e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5548ef20ba5e4651bb2965fce3916db0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a96d8f2da6f4ffa93d2e03757051e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "25e8225135f244f09308125a407c5bac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varun-bhaseen/Advance-Deep-Learning/blob/master/Multi_task_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo7kpNZnRzoB"
      },
      "source": [
        "# Multi-task Training with Transformers and NLP\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n90H9I0cMQvY"
      },
      "source": [
        "## Library setup\n",
        "\n",
        "First up, we will install the *NLP* and *Transformers* libraries. \n",
        "\n",
        "<font color='red'>**Note: After running the following cell, you will need to restart your runtime for the installation to work properly.**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlICaYzQan59",
        "outputId": "f7dff39b-bb1e-4e7c-d876-aecabe93728f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#!pip install git+https://github.com/huggingface/nlp\n",
        "!pip install transformers==2.11.0\n",
        "!pip install nlp==0.2.0"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==2.11.0 in /usr/local/lib/python3.6/dist-packages (2.11.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (0.1.94)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (0.7)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (20.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (0.7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==2.11.0) (2.4.7)\n",
            "Requirement already satisfied: nlp==0.2.0 in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from nlp==0.2.0) (4.41.1)\n",
            "Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from nlp==0.2.0) (2.0.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from nlp==0.2.0) (0.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from nlp==0.2.0) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from nlp==0.2.0) (3.0.12)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from nlp==0.2.0) (0.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from nlp==0.2.0) (1.18.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp==0.2.0) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp==0.2.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp==0.2.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp==0.2.0) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejhYiFELazOd"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "import nlp\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXdgg0ucNGvj"
      },
      "source": [
        "## Fetching our data\n",
        "\n",
        "To showcase our multi-task functionality, we will choose tasks of different formats:\n",
        "\n",
        "* STS-B: A two-sentece textual similarity scoring task. (Prediction is a real number between 1 and 5)\n",
        "* RTE: A two-sentence natural language entailment task. (Prediction is one of two classes)\n",
        "* Commonsense QA: A multiple-choice question-answering task. (Each example consists of 5 seperate text inputs, prediction is which one of the 5 choices is correct)\n",
        "\n",
        "In particular, notice that unlike STS-B and RTE, Commonsense QA consists of feeding *multiple* inputs into the transformer model. Many other tasks have weirder formats too, so our setup needs to be flexible enough to accomodate very different kinds of tasks.\n",
        "\n",
        "Now, actually getting the task data is super simple. We can simply call the `nlp.load_dataset` method, which automatically downloads the data and prepares it for use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pntb5EqgapA1",
        "outputId": "d1ec8694-ead1-498d-db54-b1ddc2a1f1e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset_dict = {\n",
        "    \"stsb\": nlp.load_dataset('glue', name=\"stsb\"),\n",
        "    \"rte\": nlp.load_dataset('glue', name=\"rte\"),\n",
        "    \"commonsense_qa\": nlp.load_dataset('commonsense_qa'),\n",
        "}"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:nlp.load:Checking /root/.cache/huggingface/datasets/5fe6ab0df8a32a3371b2e6a969d31d855a19563724fb0d0f163748c270c0ac60.2ea96febf19981fae5f13f0a43d4e2aa58bc619bc23acf06de66675f425a5538.py for additional imports.\n",
            "INFO:filelock:Lock 140692492638472 acquired on /root/.cache/huggingface/datasets/5fe6ab0df8a32a3371b2e6a969d31d855a19563724fb0d0f163748c270c0ac60.2ea96febf19981fae5f13f0a43d4e2aa58bc619bc23acf06de66675f425a5538.py.lock\n",
            "INFO:nlp.load:Found main folder for dataset https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/glue/glue.py at /usr/local/lib/python3.6/dist-packages/nlp/datasets/glue\n",
            "INFO:nlp.load:Found specific version folder for dataset https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/glue/glue.py at /usr/local/lib/python3.6/dist-packages/nlp/datasets/glue/637080968c182118f006d3ea39dd9937940e81cfffc8d79836eaae8bba307fc4\n",
            "INFO:nlp.load:Found script file from https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/glue/glue.py to /usr/local/lib/python3.6/dist-packages/nlp/datasets/glue/637080968c182118f006d3ea39dd9937940e81cfffc8d79836eaae8bba307fc4/glue.py\n",
            "INFO:nlp.load:Found dataset infos file from https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/glue/dataset_infos.json to /usr/local/lib/python3.6/dist-packages/nlp/datasets/glue/637080968c182118f006d3ea39dd9937940e81cfffc8d79836eaae8bba307fc4/dataset_infos.json\n",
            "INFO:nlp.load:Found metadata file for dataset https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/glue/glue.py at /usr/local/lib/python3.6/dist-packages/nlp/datasets/glue/637080968c182118f006d3ea39dd9937940e81cfffc8d79836eaae8bba307fc4/glue.json\n",
            "INFO:filelock:Lock 140692492638472 released on /root/.cache/huggingface/datasets/5fe6ab0df8a32a3371b2e6a969d31d855a19563724fb0d0f163748c270c0ac60.2ea96febf19981fae5f13f0a43d4e2aa58bc619bc23acf06de66675f425a5538.py.lock\n",
            "INFO:nlp.info:Loading Dataset Infos from /usr/local/lib/python3.6/dist-packages/nlp/datasets/glue/637080968c182118f006d3ea39dd9937940e81cfffc8d79836eaae8bba307fc4\n",
            "INFO:nlp.builder:Overwrite dataset info from restored data version.\n",
            "INFO:nlp.info:Loading Dataset info from /root/.cache/huggingface/datasets/glue/stsb/1.0.0\n",
            "INFO:nlp.builder:Reusing dataset glue (/root/.cache/huggingface/datasets/glue/stsb/1.0.0)\n",
            "INFO:nlp.builder:Constructing Dataset for split None, from /root/.cache/huggingface/datasets/glue/stsb/1.0.0\n",
            "INFO:nlp.load:Checking /root/.cache/huggingface/datasets/5fe6ab0df8a32a3371b2e6a969d31d855a19563724fb0d0f163748c270c0ac60.2ea96febf19981fae5f13f0a43d4e2aa58bc619bc23acf06de66675f425a5538.py for additional imports.\n",
            "INFO:filelock:Lock 140692492926424 acquired on /root/.cache/huggingface/datasets/5fe6ab0df8a32a3371b2e6a969d31d855a19563724fb0d0f163748c270c0ac60.2ea96febf19981fae5f13f0a43d4e2aa58bc619bc23acf06de66675f425a5538.py.lock\n",
            "INFO:nlp.load:Found main folder for dataset https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/glue/glue.py at /usr/local/lib/python3.6/dist-packages/nlp/datasets/glue\n",
            "INFO:nlp.load:Found specific version folder for dataset https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/glue/glue.py at /usr/local/lib/python3.6/dist-packages/nlp/datasets/glue/637080968c182118f006d3ea39dd9937940e81cfffc8d79836eaae8bba307fc4\n",
            "INFO:nlp.load:Found script file from https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/glue/glue.py to /usr/local/lib/python3.6/dist-packages/nlp/datasets/glue/637080968c182118f006d3ea39dd9937940e81cfffc8d79836eaae8bba307fc4/glue.py\n",
            "INFO:nlp.load:Found dataset infos file from https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/glue/dataset_infos.json to /usr/local/lib/python3.6/dist-packages/nlp/datasets/glue/637080968c182118f006d3ea39dd9937940e81cfffc8d79836eaae8bba307fc4/dataset_infos.json\n",
            "INFO:nlp.load:Found metadata file for dataset https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/glue/glue.py at /usr/local/lib/python3.6/dist-packages/nlp/datasets/glue/637080968c182118f006d3ea39dd9937940e81cfffc8d79836eaae8bba307fc4/glue.json\n",
            "INFO:filelock:Lock 140692492926424 released on /root/.cache/huggingface/datasets/5fe6ab0df8a32a3371b2e6a969d31d855a19563724fb0d0f163748c270c0ac60.2ea96febf19981fae5f13f0a43d4e2aa58bc619bc23acf06de66675f425a5538.py.lock\n",
            "INFO:nlp.info:Loading Dataset Infos from /usr/local/lib/python3.6/dist-packages/nlp/datasets/glue/637080968c182118f006d3ea39dd9937940e81cfffc8d79836eaae8bba307fc4\n",
            "INFO:nlp.builder:Overwrite dataset info from restored data version.\n",
            "INFO:nlp.info:Loading Dataset info from /root/.cache/huggingface/datasets/glue/rte/1.0.0\n",
            "INFO:nlp.builder:Reusing dataset glue (/root/.cache/huggingface/datasets/glue/rte/1.0.0)\n",
            "INFO:nlp.builder:Constructing Dataset for split None, from /root/.cache/huggingface/datasets/glue/rte/1.0.0\n",
            "INFO:nlp.load:Checking /root/.cache/huggingface/datasets/ea29813e78501904688a90c430f89aca3126b45c3f3f072c4a4246096a5ad0ef.29f2def772f6505fbbc27537a807141066e57bf70f50bf1e0eeb544f7eb5cf3a.py for additional imports.\n",
            "INFO:filelock:Lock 140692492637128 acquired on /root/.cache/huggingface/datasets/ea29813e78501904688a90c430f89aca3126b45c3f3f072c4a4246096a5ad0ef.29f2def772f6505fbbc27537a807141066e57bf70f50bf1e0eeb544f7eb5cf3a.py.lock\n",
            "INFO:nlp.load:Found main folder for dataset https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/commonsense_qa/commonsense_qa.py at /usr/local/lib/python3.6/dist-packages/nlp/datasets/commonsense_qa\n",
            "INFO:nlp.load:Found specific version folder for dataset https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/commonsense_qa/commonsense_qa.py at /usr/local/lib/python3.6/dist-packages/nlp/datasets/commonsense_qa/a3ca6d89a0ea731b712148dc01a2d5679a3bffd6af0896468b02834325cc2bf9\n",
            "INFO:nlp.load:Found script file from https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/commonsense_qa/commonsense_qa.py to /usr/local/lib/python3.6/dist-packages/nlp/datasets/commonsense_qa/a3ca6d89a0ea731b712148dc01a2d5679a3bffd6af0896468b02834325cc2bf9/commonsense_qa.py\n",
            "INFO:nlp.load:Found dataset infos file from https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/commonsense_qa/dataset_infos.json to /usr/local/lib/python3.6/dist-packages/nlp/datasets/commonsense_qa/a3ca6d89a0ea731b712148dc01a2d5679a3bffd6af0896468b02834325cc2bf9/dataset_infos.json\n",
            "INFO:nlp.load:Found metadata file for dataset https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/commonsense_qa/commonsense_qa.py at /usr/local/lib/python3.6/dist-packages/nlp/datasets/commonsense_qa/a3ca6d89a0ea731b712148dc01a2d5679a3bffd6af0896468b02834325cc2bf9/commonsense_qa.json\n",
            "INFO:filelock:Lock 140692492637128 released on /root/.cache/huggingface/datasets/ea29813e78501904688a90c430f89aca3126b45c3f3f072c4a4246096a5ad0ef.29f2def772f6505fbbc27537a807141066e57bf70f50bf1e0eeb544f7eb5cf3a.py.lock\n",
            "WARNING:nlp.builder:Using custom data configuration default\n",
            "INFO:nlp.info:Loading Dataset Infos from /usr/local/lib/python3.6/dist-packages/nlp/datasets/commonsense_qa/a3ca6d89a0ea731b712148dc01a2d5679a3bffd6af0896468b02834325cc2bf9\n",
            "INFO:nlp.builder:Overwrite dataset info from restored data version.\n",
            "INFO:nlp.info:Loading Dataset info from /root/.cache/huggingface/datasets/commonsense_qa/default/0.1.0\n",
            "INFO:nlp.builder:Reusing dataset commonsense_qa (/root/.cache/huggingface/datasets/commonsense_qa/default/0.1.0)\n",
            "INFO:nlp.builder:Constructing Dataset for split None, from /root/.cache/huggingface/datasets/commonsense_qa/default/0.1.0\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFTXc2iVOizO"
      },
      "source": [
        "We can show one example from each task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiP4yQMPOQVz",
        "outputId": "6598ce6b-9c03-47a0-e855-56574658a1aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for task_name, dataset in dataset_dict.items():\n",
        "    print(task_name)\n",
        "    print(dataset_dict[task_name][\"train\"][0])\n",
        "    print()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stsb\n",
            "{'sentence1': 'A plane is taking off.', 'sentence2': 'An air plane is taking off.', 'label': 5.0, 'idx': 0}\n",
            "\n",
            "rte\n",
            "{'sentence1': 'No Weapons of Mass Destruction Found in Iraq Yet.', 'sentence2': 'Weapons of Mass Destruction Found in Iraq.', 'label': 1, 'idx': 0}\n",
            "\n",
            "commonsense_qa\n",
            "{'answerKey': 'A', 'question': 'The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?', 'choices': {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['ignore', 'enforce', 'authoritarian', 'yell at', 'avoid']}}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ39AbTAPAUi"
      },
      "source": [
        "## Creating a Multi-task Model\n",
        "\n",
        "Next up, we are going to create a multi-task model. \n",
        "\n",
        "Typically, a multi-task model in the age of BERT works by having a shared BERT-style encoder transformer, and different task heads for each task.\n",
        "\n",
        "![Multi-Task 1](https://drive.google.com/uc?id=1TCdyyoHInbiZtSOUmyJN1miCj1iysygU)\n",
        "\n",
        "We could try to implement this directly in code, but there are two downsides to this approach:\n",
        "\n",
        "1. Hugging Face's Transformers has implementations for single-task models, but not modular task heads. This means we will need to do a lot of our own leg work to write our own task heads.\n",
        "2. This format assumes that the input is processed the same way in the encoder for every task. Already, Commonsense QA is problematic for this approach, since it requires the encoder to process *multiple* input sequences for a single example. Other tasks may similarly break this abstraction.\n",
        "\n",
        "Instead, we are going to do something **radically different**. We are going to create separate models for each task, but we are going make them share the same encoder. \n",
        "\n",
        "![Multi-Task 2](https://drive.google.com/uc?id=1xmghPPO5RC-TnpYP4_PpZ-TRfJF33S6p)\n",
        "\n",
        "This will serve the same goal as having the encoder be jointly trained across multiple tasks, but still retain the independent implementations of each model. As such, we can use the existing task-model implementations in Transformers, such as `RobertaForSequenceClassification` and `RobertaForMultipleChoice`.\n",
        "\n",
        "Importantly, the shared encoder ensures that during training, all updates will update the same encoder weighs, and also **does not consume any additional GPU memory**.\n",
        "\n",
        "First, we define our `MultitaskModel` class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVX5hFlzmLka"
      },
      "source": [
        "class MultitaskModel(transformers.PreTrainedModel):\n",
        "    def __init__(self, encoder, taskmodels_dict):\n",
        "        \"\"\"\n",
        "        Setting MultitaskModel up as a PretrainedModel allows us\n",
        "        to take better advantage of Trainer features\n",
        "        \"\"\"\n",
        "        super().__init__(transformers.PretrainedConfig())\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.taskmodels_dict = nn.ModuleDict(taskmodels_dict)\n",
        "\n",
        "    @classmethod\n",
        "    def create(cls, model_name, model_type_dict, model_config_dict):\n",
        "        \"\"\"\n",
        "        This creates a MultitaskModel using the model class and config objects\n",
        "        from single-task models. \n",
        "\n",
        "        We do this by creating each single-task model, and having them share\n",
        "        the same encoder transformer.\n",
        "        \"\"\"\n",
        "        shared_encoder = None\n",
        "        taskmodels_dict = {}\n",
        "        for task_name, model_type in model_type_dict.items():\n",
        "            model = model_type.from_pretrained(\n",
        "                model_name, \n",
        "                config=model_config_dict[task_name],\n",
        "            )\n",
        "            if shared_encoder is None:\n",
        "                shared_encoder = getattr(model, cls.get_encoder_attr_name(model))\n",
        "            else:\n",
        "                setattr(model, cls.get_encoder_attr_name(model), shared_encoder)\n",
        "            taskmodels_dict[task_name] = model\n",
        "        return cls(encoder=shared_encoder, taskmodels_dict=taskmodels_dict)\n",
        "\n",
        "    @classmethod\n",
        "    def get_encoder_attr_name(cls, model):\n",
        "        \"\"\"\n",
        "        The encoder transformer is named differently in each model \"architecture\".\n",
        "        This method lets us get the name of the encoder attribute\n",
        "        \"\"\"\n",
        "        model_class_name = model.__class__.__name__\n",
        "        if model_class_name.startswith(\"Bert\"):\n",
        "            return \"bert\"\n",
        "        elif model_class_name.startswith(\"Roberta\"):\n",
        "            return \"roberta\"\n",
        "        elif model_class_name.startswith(\"Albert\"):\n",
        "            return \"albert\"\n",
        "        else:\n",
        "            raise KeyError(f\"Add support for new model {model_class_name}\")\n",
        "\n",
        "    def forward(self, task_name, **kwargs):\n",
        "        return self.taskmodels_dict[task_name](**kwargs)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zSZsp8Cb7gd"
      },
      "source": [
        "As described above, the `MultitaskModel` class consists of only two components - the shared \"encoder\", a dictionary to the individual task models. Now, we can simply create the corresponding task models by supplying the invidual model classes and model configs. We will use Transformers' AutoModels to further automate the choice of model class given a model architecture (in our case, let's use `roberta-base`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_sosFINo24B",
        "outputId": "0e0317a5-d77d-48f2-ea39-3d2f1ea5af0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_name = \"roberta-base\"\n",
        "multitask_model = MultitaskModel.create(\n",
        "    model_name=model_name,\n",
        "    model_type_dict={\n",
        "        \"stsb\": transformers.AutoModelForSequenceClassification,\n",
        "        \"rte\": transformers.AutoModelForSequenceClassification,\n",
        "        \"commonsense_qa\": transformers.AutoModelForMultipleChoice,\n",
        "    },\n",
        "    model_config_dict={\n",
        "        \"stsb\": transformers.AutoConfig.from_pretrained(model_name, num_labels=1),\n",
        "        \"rte\": transformers.AutoConfig.from_pretrained(model_name, num_labels=2),\n",
        "        \"commonsense_qa\": transformers.AutoConfig.from_pretrained(model_name),\n",
        "    },\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "INFO:transformers.configuration_utils:Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "INFO:transformers.configuration_utils:Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "INFO:transformers.configuration_utils:Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "INFO:transformers.modeling_utils:Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "INFO:transformers.modeling_utils:Weights from pretrained model not used in RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
            "INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "INFO:transformers.modeling_utils:Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "INFO:transformers.modeling_utils:Weights from pretrained model not used in RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
            "INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "INFO:transformers.modeling_utils:Weights of RobertaForMultipleChoice not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "INFO:transformers.modeling_utils:Weights from pretrained model not used in RobertaForMultipleChoice: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxSAQ6q4O-uL"
      },
      "source": [
        "To confirm that all three task-models use the same encoder, we can check the data pointers of the respective encoders. In this case, we'll check that the word embeddings in each model all point to the same memory location."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrtS3ZeSsoZw",
        "outputId": "c6e9fe4d-7b6c-46ea-e157-8e61f817acfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if model_name.startswith(\"roberta-\"):\n",
        "    print(multitask_model.encoder.embeddings.word_embeddings.weight.data_ptr())\n",
        "    print(multitask_model.taskmodels_dict[\"stsb\"].roberta.embeddings.word_embeddings.weight.data_ptr())\n",
        "    print(multitask_model.taskmodels_dict[\"rte\"].roberta.embeddings.word_embeddings.weight.data_ptr())\n",
        "    print(multitask_model.taskmodels_dict[\"commonsense_qa\"].roberta.embeddings.word_embeddings.weight.data_ptr())\n",
        "else:\n",
        "    print(\"Exercise for the reader: add a check for other model architectures =)\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4248076288\n",
            "4248076288\n",
            "4248076288\n",
            "4248076288\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PujQR2HkPTRk"
      },
      "source": [
        "## Processing our task data\n",
        "\n",
        "We have created a dictionary of NLP datasets above, but we need to do a little more work to convert the respective task data into model inputs.\n",
        "\n",
        "We'll start by first getting the tokenizer corresponding to our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n96ifPukDkb",
        "outputId": "3e68cf16-29c5-4675-f27b-79b194da69e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "INFO:transformers.configuration_utils:Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5BubjFwPySD"
      },
      "source": [
        "Next, we'll write some short functions to convert from raw text to tokenized text inputs. \n",
        "\n",
        "* Both STS-B and RTE and two-sentence input tasks, so we will concatenate them with the corresponding special tokens. (The tokenizer's `batch_encode_plus` method handles this for us.) So, the input might look like: \n",
        "\n",
        "```\n",
        "['<s>', 'This', 'is', 'my', 'premise', '.', '</s>', '</s>', 'This', 'is', 'my', 'hypothesis', '.', '</s>']\n",
        "```\n",
        "\n",
        "* CommonsenseQA, is a multiple choice task. A single example consists of a question, a five possible answer choices. We will feed the model inputs concatenated like `QUESTION + CHOICE_1`, `QUESTION + CHOICE_2` and so on. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSeBYKCublmo"
      },
      "source": [
        "max_length = 128\n",
        "\n",
        "def convert_to_stsb_features(example_batch):\n",
        "    inputs = list(zip(example_batch['sentence1'], example_batch['sentence2']))\n",
        "    features = tokenizer.batch_encode_plus(\n",
        "        inputs, max_length=max_length, pad_to_max_length=True\n",
        "    )\n",
        "    features[\"labels\"] = example_batch[\"label\"]\n",
        "    return features\n",
        "\n",
        "def convert_to_rte_features(example_batch):\n",
        "    inputs = list(zip(example_batch['sentence1'], example_batch['sentence2']))\n",
        "    features = tokenizer.batch_encode_plus(\n",
        "        inputs, max_length=max_length, pad_to_max_length=True\n",
        "    )\n",
        "    features[\"labels\"] = example_batch[\"label\"]\n",
        "    return features\n",
        "\n",
        "def convert_to_commonsense_qa_features(example_batch):\n",
        "    num_examples = len(example_batch[\"question\"])\n",
        "    num_choices = len(example_batch[\"choices\"][0][\"text\"])\n",
        "    features = {}\n",
        "    for example_i in range(num_examples):\n",
        "        choices_inputs = tokenizer.batch_encode_plus(\n",
        "            list(zip(\n",
        "                [example_batch[\"question\"][example_i]] * num_choices,\n",
        "                example_batch[\"choices\"][example_i][\"text\"],\n",
        "            )),\n",
        "            max_length=max_length, pad_to_max_length=True,\n",
        "        )\n",
        "        for k, v in choices_inputs.items():\n",
        "            if k not in features:\n",
        "                features[k] = []\n",
        "            features[k].append(v)\n",
        "    labels2id = {char: i for i, char in enumerate(\"ABCDE\")}\n",
        "    # Dummy answers for test\n",
        "    if example_batch[\"answerKey\"][0]:\n",
        "        features[\"labels\"] = [labels2id[ans] for ans in example_batch[\"answerKey\"]]\n",
        "    else:\n",
        "        features[\"labels\"] = [0] * num_examples    \n",
        "    return features\n",
        "\n",
        "convert_func_dict = {\n",
        "    \"stsb\": convert_to_stsb_features,\n",
        "    \"rte\": convert_to_rte_features,\n",
        "    \"commonsense_qa\": convert_to_commonsense_qa_features,\n",
        "}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eULIAQ9WRYXn"
      },
      "source": [
        "Now that we have defined the above functions, we can use `dataset.map` method available in the NLP library to apply the functions over our entire datasets. The NLP library that handles the mapping efficiently and caches the features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcLnS85Hkhbf",
        "outputId": "12715f8c-2e3c-462d-f0f7-53493d191b5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "columns_dict = {\n",
        "    \"stsb\": ['input_ids', 'attention_mask', 'labels'],\n",
        "    \"rte\": ['input_ids', 'attention_mask', 'labels'],\n",
        "    \"commonsense_qa\": ['input_ids', 'attention_mask', 'labels'],\n",
        "}\n",
        "\n",
        "features_dict = {}\n",
        "for task_name, dataset in dataset_dict.items():\n",
        "    features_dict[task_name] = {}\n",
        "    for phase, phase_dataset in dataset.items():\n",
        "        features_dict[task_name][phase] = phase_dataset.map(\n",
        "            convert_func_dict[task_name],\n",
        "            batched=True,\n",
        "            load_from_cache_file=False,\n",
        "        )\n",
        "        print(task_name, phase, len(phase_dataset), len(features_dict[task_name][phase]))\n",
        "        features_dict[task_name][phase].set_format(\n",
        "            type=\"torch\", \n",
        "            columns=columns_dict[task_name],\n",
        "        )\n",
        "        print(task_name, phase, len(phase_dataset), len(features_dict[task_name][phase]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:nlp.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/glue/stsb/1.0.0/cache-d2b0e2b1e353f1b9fbe0725471db143f.arrow\n",
            "100%|██████████| 6/6 [00:01<00:00,  3.57it/s]\n",
            "INFO:nlp.arrow_writer:Done writing 5749 examples in 12666815 bytes /root/.cache/huggingface/datasets/glue/stsb/1.0.0/cache-d2b0e2b1e353f1b9fbe0725471db143f.arrow.\n",
            "INFO:nlp.arrow_dataset:Set __getitem__(key) output type to torch for ['input_ids', 'attention_mask', 'labels'] columns  (when key is int or slice) and don't output other (un-formated) columns.\n",
            "INFO:nlp.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/glue/stsb/1.0.0/cache-aec11a0dac2eda110e765a5c78c608aa.arrow\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "stsb train 5749 5749\n",
            "stsb train 5749 5749\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  4.59it/s]\n",
            "INFO:nlp.arrow_writer:Done writing 1500 examples in 3324096 bytes /root/.cache/huggingface/datasets/glue/stsb/1.0.0/cache-aec11a0dac2eda110e765a5c78c608aa.arrow.\n",
            "INFO:nlp.arrow_dataset:Set __getitem__(key) output type to torch for ['input_ids', 'attention_mask', 'labels'] columns  (when key is int or slice) and don't output other (un-formated) columns.\n",
            "INFO:nlp.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/glue/stsb/1.0.0/cache-593c638955a8714e57a2c4867a2ef077.arrow\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "stsb validation 1500 1500\n",
            "stsb validation 1500 1500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  6.78it/s]\n",
            "INFO:nlp.arrow_writer:Done writing 1379 examples in 3027294 bytes /root/.cache/huggingface/datasets/glue/stsb/1.0.0/cache-593c638955a8714e57a2c4867a2ef077.arrow.\n",
            "INFO:nlp.arrow_dataset:Set __getitem__(key) output type to torch for ['input_ids', 'attention_mask', 'labels'] columns  (when key is int or slice) and don't output other (un-formated) columns.\n",
            "INFO:nlp.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/glue/rte/1.0.0/cache-38be6965ba491702cf4515ce3bf905d2.arrow\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "stsb test 1379 1379\n",
            "stsb test 1379 1379\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  2.31it/s]\n",
            "INFO:nlp.arrow_writer:Done writing 2490 examples in 5996688 bytes /root/.cache/huggingface/datasets/glue/rte/1.0.0/cache-38be6965ba491702cf4515ce3bf905d2.arrow.\n",
            "INFO:nlp.arrow_dataset:Set __getitem__(key) output type to torch for ['input_ids', 'attention_mask', 'labels'] columns  (when key is int or slice) and don't output other (un-formated) columns.\n",
            "INFO:nlp.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/glue/rte/1.0.0/cache-24ce8344dcbe3bd232bdc5bc71e48d3b.arrow\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.77it/s]\n",
            "INFO:nlp.arrow_writer:Done writing 277 examples in 663580 bytes /root/.cache/huggingface/datasets/glue/rte/1.0.0/cache-24ce8344dcbe3bd232bdc5bc71e48d3b.arrow.\n",
            "INFO:nlp.arrow_dataset:Set __getitem__(key) output type to torch for ['input_ids', 'attention_mask', 'labels'] columns  (when key is int or slice) and don't output other (un-formated) columns.\n",
            "INFO:nlp.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/glue/rte/1.0.0/cache-fb596d2fec55c5205924eefa5c903826.arrow\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rte train 2490 2490\n",
            "rte train 2490 2490\n",
            "rte validation 277 277\n",
            "rte validation 277 277\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  2.27it/s]\n",
            "INFO:nlp.arrow_writer:Done writing 3000 examples in 7178101 bytes /root/.cache/huggingface/datasets/glue/rte/1.0.0/cache-fb596d2fec55c5205924eefa5c903826.arrow.\n",
            "INFO:nlp.arrow_dataset:Set __getitem__(key) output type to torch for ['input_ids', 'attention_mask', 'labels'] columns  (when key is int or slice) and don't output other (un-formated) columns.\n",
            "INFO:nlp.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/commonsense_qa/default/0.1.0/cache-b7200320d1603b178797c3e10a70c72a.arrow\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rte test 3000 3000\n",
            "rte test 3000 3000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:08<00:00,  1.21it/s]\n",
            "INFO:nlp.arrow_writer:Done writing 9741 examples in 102030077 bytes /root/.cache/huggingface/datasets/commonsense_qa/default/0.1.0/cache-b7200320d1603b178797c3e10a70c72a.arrow.\n",
            "INFO:nlp.arrow_dataset:Set __getitem__(key) output type to torch for ['input_ids', 'attention_mask', 'labels'] columns  (when key is int or slice) and don't output other (un-formated) columns.\n",
            "INFO:nlp.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/commonsense_qa/default/0.1.0/cache-55713c9b25e6141f0385d7a21a89818a.arrow\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "commonsense_qa train 9741 9741\n",
            "commonsense_qa train 9741 9741\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.03it/s]\n",
            "INFO:nlp.arrow_writer:Done writing 1221 examples in 12786529 bytes /root/.cache/huggingface/datasets/commonsense_qa/default/0.1.0/cache-55713c9b25e6141f0385d7a21a89818a.arrow.\n",
            "INFO:nlp.arrow_dataset:Set __getitem__(key) output type to torch for ['input_ids', 'attention_mask', 'labels'] columns  (when key is int or slice) and don't output other (un-formated) columns.\n",
            "INFO:nlp.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/commonsense_qa/default/0.1.0/cache-e40d5adaeb67d334a4bdad765d7f911e.arrow\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "commonsense_qa validation 1221 1221\n",
            "commonsense_qa validation 1221 1221\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.14it/s]\n",
            "INFO:nlp.arrow_writer:Done writing 1140 examples in 11940278 bytes /root/.cache/huggingface/datasets/commonsense_qa/default/0.1.0/cache-e40d5adaeb67d334a4bdad765d7f911e.arrow.\n",
            "INFO:nlp.arrow_dataset:Set __getitem__(key) output type to torch for ['input_ids', 'attention_mask', 'labels'] columns  (when key is int or slice) and don't output other (un-formated) columns.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "commonsense_qa test 1140 1140\n",
            "commonsense_qa test 1140 1140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x33Yu15nSurv"
      },
      "source": [
        "As a recap:\n",
        "\n",
        "* We have created our multi-task model by fusing several single-task Transformer models\n",
        "* We have created a (cached) dictionary of featurized inputs for each of our tasks, using NLP dataset\n",
        "\n",
        "Next up, we need to \n",
        "\n",
        "1. Set up our data loading\n",
        "2. Set up our Trainer \n",
        "3. Start training!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4N7IF9hTR7m"
      },
      "source": [
        "## Preparing a multi-task data loader and Trainer\n",
        "\n",
        "Setting up a multi-task data loader should be simple in principle - we simply need to sample from multiple single-task data loaders with some probability, and feed each batch to the multi-task model above. Of course, along with each batch, we also need to tell the model what task it is for, so `MultitaskModel` knows to use the right corresponding task-model.\n",
        "\n",
        "However, because we want to use the built-in `Trainer` class in Transformers, this gets a little tricky, since the `Trainer` expects a single data loader, and expects a very specific format of per-batch data. This slice of code is somewhat of a hack around that constraint. (This can become a lot more streamlined with some tweaks to the Trainer code from the Hugging Face folks =))\n",
        "\n",
        "We need to define a `MultitaskDataloader` that combines several data loaders into a single \"data loader\" - not so different from our multi-task model above! This `MultitaskDataloader` should do what we described: sample from different single-task data loaders, and yield a task batch and the corresponding task name (we're going to add the `task_name` to the batch data).\n",
        "\n",
        "We will also need to override the `get_train_dataloader` method of the `Trainer` to play well with our `MultitaskDataloader`. We do this with a `MultitaskTrainer`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdUbpAIZzWce"
      },
      "source": [
        "import dataclasses\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from transformers.training_args import is_tpu_available\n",
        "from transformers.trainer import get_tpu_sampler\n",
        "from transformers.data.data_collator import DataCollator, InputDataClass\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.utils.data.sampler import RandomSampler\n",
        "from typing import List, Union, Dict\n",
        "\n",
        "\n",
        "class NLPDataCollator(DataCollator):\n",
        "    \"\"\"\n",
        "    Extending the existing DataCollator to work with NLP dataset batches\n",
        "    \"\"\"\n",
        "    def collate_batch(self, features: List[Union[InputDataClass, Dict]]) -> Dict[str, torch.Tensor]:\n",
        "        first = features[0]\n",
        "        if isinstance(first, dict):\n",
        "          # NLP data sets current works presents features as lists of dictionary\n",
        "          # (one per example), so we  will adapt the collate_batch logic for that\n",
        "          if \"labels\" in first and first[\"labels\"] is not None:\n",
        "              if first[\"labels\"].dtype == torch.int64:\n",
        "                  labels = torch.tensor([f[\"labels\"] for f in features], dtype=torch.long)\n",
        "              else:\n",
        "                  labels = torch.tensor([f[\"labels\"] for f in features], dtype=torch.float)\n",
        "              batch = {\"labels\": labels}\n",
        "          for k, v in first.items():\n",
        "              if k != \"labels\" and v is not None and not isinstance(v, str):\n",
        "                  batch[k] = torch.stack([f[k] for f in features])\n",
        "          return batch\n",
        "        else:\n",
        "          # otherwise, revert to using the default collate_batch\n",
        "          return DefaultDataCollator().collate_batch(features)\n",
        "\n",
        "\n",
        "class StrIgnoreDevice(str):\n",
        "    \"\"\"\n",
        "    This is a hack. The Trainer is going call .to(device) on every input\n",
        "    value, but we need to pass in an additional `task_name` string.\n",
        "    This prevents it from throwing an error\n",
        "    \"\"\"\n",
        "    def to(self, device):\n",
        "        return self\n",
        "\n",
        "\n",
        "class DataLoaderWithTaskname:\n",
        "    \"\"\"\n",
        "    Wrapper around a DataLoader to also yield a task name\n",
        "    \"\"\"\n",
        "    def __init__(self, task_name, data_loader):\n",
        "        self.task_name = task_name\n",
        "        self.data_loader = data_loader\n",
        "\n",
        "        self.batch_size = data_loader.batch_size\n",
        "        self.dataset = data_loader.dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_loader)\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for batch in self.data_loader:\n",
        "            batch[\"task_name\"] = StrIgnoreDevice(self.task_name)\n",
        "            yield batch\n",
        "\n",
        "\n",
        "class MultitaskDataloader:\n",
        "    \"\"\"\n",
        "    Data loader that combines and samples from multiple single-task\n",
        "    data loaders.\n",
        "    \"\"\"\n",
        "    def __init__(self, dataloader_dict):\n",
        "        self.dataloader_dict = dataloader_dict\n",
        "        self.num_batches_dict = {\n",
        "            task_name: len(dataloader) \n",
        "            for task_name, dataloader in self.dataloader_dict.items()\n",
        "        }\n",
        "        self.task_name_list = list(self.dataloader_dict)\n",
        "        self.dataset = [None] * sum(\n",
        "            len(dataloader.dataset) \n",
        "            for dataloader in self.dataloader_dict.values()\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return sum(self.num_batches_dict.values())\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"\n",
        "        For each batch, sample a task, and yield a batch from the respective\n",
        "        task Dataloader.\n",
        "\n",
        "        We use size-proportional sampling, but you could easily modify this\n",
        "        to sample from some-other distribution.\n",
        "        \"\"\"\n",
        "        task_choice_list = []\n",
        "        for i, task_name in enumerate(self.task_name_list):\n",
        "            task_choice_list += [i] * self.num_batches_dict[task_name]\n",
        "        task_choice_list = np.array(task_choice_list)\n",
        "        np.random.shuffle(task_choice_list)\n",
        "        dataloader_iter_dict = {\n",
        "            task_name: iter(dataloader) \n",
        "            for task_name, dataloader in self.dataloader_dict.items()\n",
        "        }\n",
        "        for task_choice in task_choice_list:\n",
        "            task_name = self.task_name_list[task_choice]\n",
        "            yield next(dataloader_iter_dict[task_name])    \n",
        "\n",
        "class MultitaskTrainer(transformers.Trainer):\n",
        "\n",
        "    def get_single_train_dataloader(self, task_name, train_dataset):\n",
        "        \"\"\"\n",
        "        Create a single-task data loader that also yields task names\n",
        "        \"\"\"\n",
        "        if self.train_dataset is None:\n",
        "            raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
        "        if is_tpu_available():\n",
        "            train_sampler = get_tpu_sampler(train_dataset)\n",
        "        else:\n",
        "            train_sampler = (\n",
        "                RandomSampler(train_dataset)\n",
        "                if self.args.local_rank == -1\n",
        "                else DistributedSampler(train_dataset)\n",
        "            )\n",
        "\n",
        "        data_loader = DataLoaderWithTaskname(\n",
        "            task_name=task_name,\n",
        "            data_loader=DataLoader(\n",
        "              train_dataset,\n",
        "              batch_size=self.args.train_batch_size,\n",
        "              sampler=train_sampler,\n",
        "              collate_fn=self.data_collator.collate_batch,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        if is_tpu_available():\n",
        "            data_loader = pl.ParallelLoader(\n",
        "                data_loader, [self.args.device]\n",
        "            ).per_device_loader(self.args.device)\n",
        "        return data_loader\n",
        "\n",
        "    def get_train_dataloader(self):\n",
        "        \"\"\"\n",
        "        Returns a MultitaskDataloader, which is not actually a Dataloader\n",
        "        but an iterable that returns a generator that samples from each \n",
        "        task Dataloader\n",
        "        \"\"\"\n",
        "        return MultitaskDataloader({\n",
        "            task_name: self.get_single_train_dataloader(task_name, task_dataset)\n",
        "            for task_name, task_dataset in self.train_dataset.items()\n",
        "        })"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AtQfkWxVUSJ"
      },
      "source": [
        "## Time to train!\n",
        "\n",
        "Okay, we have done all the hard work, now it is time for it to pay off. We can now simply create our `MultitaskTrainer`, and start training! \n",
        "\n",
        "(This takes about ~45 minutes for me on Colab, but it will depend on the GPU you are allocated.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4YUxdIZz3_i",
        "outputId": "2ff0a052-58cc-4b46-b988-375ee6a41981",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817,
          "referenced_widgets": [
            "408feb192a934ca5b3156794eacd8ec1",
            "82849cfd80b34cfd8838ffe70d3a4809",
            "f2795e8c7e2947ea86a8ea895555c79b",
            "16a8970e62854d1bb812a9a452342245",
            "c5f9f869d2424ec68a707d7a804ca007",
            "25d07157b20247dc9146e38f7c834452",
            "f74240ffa38d41c88125b55a41103638",
            "226d612a1e1640eca87240ef892f41c3",
            "c51176cb245b4040a5986970576a1f72",
            "4e32b0b6cbfc402ca899438780059715",
            "c0023455d0884d08bf6e1ef05c780d3c",
            "6c3a5cbdb0e44875ae00cb7476a5937e",
            "103b623c4971417ebb6f691d12258114",
            "bd42204c6b594236981bd17435db2b64",
            "340d2c7f2ad44332b1ca8d8c9f7e55c2",
            "36c09a41c90d4836b0e4a3556bca0873",
            "a6d2586ff27c4113b927a475c5476247",
            "935b6da3a13a42f7900c3c81f275379d",
            "10120c83fc7e4f57892e615697e76a62",
            "4398ecc5150947a9888bfa6a686bdd52",
            "4f72f49bfd5040bf92ce763f4ebb2660",
            "a9bbf8ee8f704020a355382e19739d26",
            "714b16ed040b46ceb50c25f80eb415d7",
            "8987b636d706476d9219fcfc1c510d6c",
            "aebee5c0bc4e4a2bbb816d49baa23d21",
            "d5d57ed10d984ee99fd13f8f8c473106",
            "ccfd7cba354749e1afd7abca9abda423",
            "967d47cdb14a4b98921b79189c803535",
            "b7fc9a60e7b84ce59584f317dd37f35b",
            "abeb9e247eac423197f2adf4bc4a93d9",
            "242fbc40994a40c99ec31a518e7acb2b",
            "38fef6b698854ccbb06975272a63acaa"
          ]
        }
      },
      "source": [
        "train_dataset = {\n",
        "    task_name: dataset[\"train\"] \n",
        "    for task_name, dataset in features_dict.items()\n",
        "}\n",
        "trainer = MultitaskTrainer(\n",
        "    model=multitask_model,\n",
        "    args=transformers.TrainingArguments(\n",
        "        output_dir=\"./models/multitask_model\",\n",
        "        overwrite_output_dir=True,\n",
        "        learning_rate=1e-5,\n",
        "        do_train=True,\n",
        "        num_train_epochs=3,\n",
        "        # Adjust batch size if this doesn't fit on the Colab GPU\n",
        "        per_device_train_batch_size=8,  \n",
        "        save_steps=3000,\n",
        "    ),\n",
        "    data_collator=NLPDataCollator(),\n",
        "    train_dataset=train_dataset,\n",
        ")\n",
        "trainer.train()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.training_args:PyTorch: setting up devices\n",
            "INFO:transformers.trainer:You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.\n",
            "INFO:transformers.trainer:***** Running training *****\n",
            "INFO:transformers.trainer:  Num examples = 17980\n",
            "INFO:transformers.trainer:  Num Epochs = 3\n",
            "INFO:transformers.trainer:  Instantaneous batch size per device = 8\n",
            "INFO:transformers.trainer:  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "INFO:transformers.trainer:  Gradient Accumulation steps = 1\n",
            "INFO:transformers.trainer:  Total optimization steps = 6747\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "408feb192a934ca5b3156794eacd8ec1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c51176cb245b4040a5986970576a1f72",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2249.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{\"loss\": 1.787500565469265, \"learning_rate\": 9.258929894768046e-06, \"epoch\": 0.2223210315695865, \"step\": 500}\n",
            "{\"loss\": 1.213834976002574, \"learning_rate\": 8.51785978953609e-06, \"epoch\": 0.444642063139173, \"step\": 1000}\n",
            "{\"loss\": 1.0130841791629792, \"learning_rate\": 7.776789684304135e-06, \"epoch\": 0.6669630947087595, \"step\": 1500}\n",
            "{\"loss\": 0.9762297323495149, \"learning_rate\": 7.035719579072181e-06, \"epoch\": 0.889284126278346, \"step\": 2000}\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6d2586ff27c4113b927a475c5476247",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2249.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{\"loss\": 0.8998755369633437, \"learning_rate\": 6.294649473840225e-06, \"epoch\": 1.1116051578479325, \"step\": 2500}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.trainer:Saving model checkpoint to ./models/multitask_model/checkpoint-3000\n",
            "INFO:transformers.configuration_utils:Configuration saved in ./models/multitask_model/checkpoint-3000/config.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"loss\": 0.8138350650072098, \"learning_rate\": 5.553579368608271e-06, \"epoch\": 1.333926189417519, \"step\": 3000}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.modeling_utils:Model weights saved in ./models/multitask_model/checkpoint-3000/pytorch_model.bin\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"loss\": 0.8032157642245292, \"learning_rate\": 4.812509263376316e-06, \"epoch\": 1.5562472209871054, \"step\": 3500}\n",
            "{\"loss\": 0.7588491155952215, \"learning_rate\": 4.071439158144361e-06, \"epoch\": 1.778568252556692, \"step\": 4000}\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aebee5c0bc4e4a2bbb816d49baa23d21",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2249.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{\"loss\": 0.7490080942511559, \"learning_rate\": 3.3303690529124056e-06, \"epoch\": 2.0008892841262784, \"step\": 4500}\n",
            "{\"loss\": 0.6669074837937952, \"learning_rate\": 2.589298947680451e-06, \"epoch\": 2.223210315695865, \"step\": 5000}\n",
            "{\"loss\": 0.6619225768074394, \"learning_rate\": 1.8482288424484956e-06, \"epoch\": 2.4455313472654514, \"step\": 5500}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.trainer:Saving model checkpoint to ./models/multitask_model/checkpoint-6000\n",
            "INFO:transformers.configuration_utils:Configuration saved in ./models/multitask_model/checkpoint-6000/config.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"loss\": 0.646769627906382, \"learning_rate\": 1.1071587372165407e-06, \"epoch\": 2.667852378835038, \"step\": 6000}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.modeling_utils:Model weights saved in ./models/multitask_model/checkpoint-6000/pytorch_model.bin\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"loss\": 0.6380800472348929, \"learning_rate\": 3.660886319845858e-07, \"epoch\": 2.8901734104046244, \"step\": 6500}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.trainer:\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=6747, training_loss=0.8853383812392458)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBQQVj67j7kn"
      },
      "source": [
        "All done! Now, we can evaluate our multi-task model on all three tasks. In this case, we can simply use single-task data loaders, since we are evaluating each task individually.\n",
        "\n",
        "We will use the (private) `_prediction_loop` method from the Trainer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk6aj8UmBV9Q",
        "outputId": "43ccceb7-35e3-4c70-9dd1-17024109c542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365,
          "referenced_widgets": [
            "98dee5ab22b6444e957fba46fa955775",
            "3b904ff21eb54b10b06892792a9a728c",
            "6b5f0f5ddfa044a9bf3e3690683b2e8a",
            "2ccd3fcc896547cb8c0701fe89bd3229",
            "171781e7a75245959159d1edf6791239",
            "762caf8d863d496d8a079d24ee9fbc4f",
            "1a457294496e470a833d46121c4a59f9",
            "c7f657855c36467db03502b74f939170",
            "c66495eb316244d4830a01144f4c4c08",
            "28047a01ac0845efb1273f6ee5224a55",
            "b13aef38574f4421a69b726403429606",
            "1b00746401fa4a589fd30bccd65b9db7",
            "15740bba74994996a0acb477d69e4f56",
            "84161a10c67845d59230412237990852",
            "91bf2ea28d594836a6deedf67f2b93f6",
            "c6378be1a2df44399f337d30f1b69c54",
            "3ebec1bcde124839b1909627c25ce808",
            "c70475cd0a6a4720be9e4daf2244a839",
            "35e1c8f514034fbfbdf96a00cd1e6a35",
            "82c0a3ff451248d29464276b391e3ee6",
            "37ff88b825594d9fb9f38ab70328df59",
            "ae2556cc14794d19bdd00d3373f19791",
            "163b8f5f7ae245ba9b10a4c2cfbe034b",
            "3d2bd8364efe476992b2c274dbb00da6"
          ]
        }
      },
      "source": [
        "preds_dict = {}\n",
        "for task_name in [\"rte\", \"stsb\", \"commonsense_qa\"]:\n",
        "    eval_dataloader = DataLoaderWithTaskname(\n",
        "        task_name,\n",
        "        trainer.get_eval_dataloader(eval_dataset=features_dict[task_name][\"validation\"])\n",
        "    )\n",
        "    print(eval_dataloader.data_loader.collate_fn)\n",
        "    preds_dict[task_name] = trainer._prediction_loop(\n",
        "        eval_dataloader, \n",
        "        description=f\"Validation: {task_name}\",\n",
        "    )"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.trainer:***** Running Validation: rte *****\n",
            "INFO:transformers.trainer:  Num examples = 277\n",
            "INFO:transformers.trainer:  Batch size = 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<bound method NLPDataCollator.collate_batch of <__main__.NLPDataCollator object at 0x7ff58926df60>>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98dee5ab22b6444e957fba46fa955775",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Validation: rte', max=35.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.trainer:***** Running Validation: stsb *****\n",
            "INFO:transformers.trainer:  Num examples = 1500\n",
            "INFO:transformers.trainer:  Batch size = 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "<bound method NLPDataCollator.collate_batch of <__main__.NLPDataCollator object at 0x7ff58926df60>>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c66495eb316244d4830a01144f4c4c08",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Validation: stsb', max=188.0, style=ProgressStyle(descrip…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.trainer:***** Running Validation: commonsense_qa *****\n",
            "INFO:transformers.trainer:  Num examples = 1221\n",
            "INFO:transformers.trainer:  Batch size = 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "<bound method NLPDataCollator.collate_batch of <__main__.NLPDataCollator object at 0x7ff58926df60>>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ebec1bcde124839b1909627c25ce808",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Validation: commonsense_qa', max=153.0, style=ProgressSty…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzHyYue7rnBz"
      },
      "source": [
        "Now that we have all the predictions, let's go ahead and score them. The NLP library also has built-in metrics for the GLUE tasks (which includes STS-B and RTE), but not for Commonsense QA. Thankfully, Commonsense QA's evaluation metric is simple accuracy, which we can compute easily."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vXMkkvZJuKo",
        "outputId": "68839e4c-ecec-4685-c13f-b71be892c463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422,
          "referenced_widgets": [
            "9022705ae74e4b8ab3c9b2a43211817b",
            "ca37cb2bec294cf1bcf88fbec529e52d",
            "a8dc954adfcb4cfd86c70836d6435d45",
            "1da42958a52b495ca24d8ae491751411",
            "702f7ed64e874a4687f773c62dbbd8e5",
            "5548ef20ba5e4651bb2965fce3916db0",
            "9a96d8f2da6f4ffa93d2e03757051e1d",
            "25e8225135f244f09308125a407c5bac"
          ]
        }
      },
      "source": [
        "# Evalute RTE\n",
        "nlp.load_metric('glue', name=\"rte\").compute(\n",
        "    np.argmax(preds_dict[\"rte\"].predictions, axis=1),\n",
        "    preds_dict[\"rte\"].label_ids,\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 140692542420136 acquired on /root/.cache/huggingface/datasets/ee5b3a098be9a0d5be9e705b2abdaf1c7bf81ebf279e965db8dbd7db418efa32.f1fd3484ce65950de4cdde6c3e2f332d0fc7dd681ea11d91ede37857561b30b4.py.lock\n",
            "INFO:nlp.utils.file_utils:https://s3.amazonaws.com/datasets.huggingface.co/nlp/metrics/glue/glue.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/tmpy7wtw96a\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9022705ae74e4b8ab3c9b2a43211817b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=4151.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:nlp.utils.file_utils:storing https://s3.amazonaws.com/datasets.huggingface.co/nlp/metrics/glue/glue.py in cache at /root/.cache/huggingface/datasets/ee5b3a098be9a0d5be9e705b2abdaf1c7bf81ebf279e965db8dbd7db418efa32.f1fd3484ce65950de4cdde6c3e2f332d0fc7dd681ea11d91ede37857561b30b4.py\n",
            "INFO:nlp.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/ee5b3a098be9a0d5be9e705b2abdaf1c7bf81ebf279e965db8dbd7db418efa32.f1fd3484ce65950de4cdde6c3e2f332d0fc7dd681ea11d91ede37857561b30b4.py\n",
            "INFO:filelock:Lock 140692542420136 released on /root/.cache/huggingface/datasets/ee5b3a098be9a0d5be9e705b2abdaf1c7bf81ebf279e965db8dbd7db418efa32.f1fd3484ce65950de4cdde6c3e2f332d0fc7dd681ea11d91ede37857561b30b4.py.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:nlp.load:Checking /root/.cache/huggingface/datasets/ee5b3a098be9a0d5be9e705b2abdaf1c7bf81ebf279e965db8dbd7db418efa32.f1fd3484ce65950de4cdde6c3e2f332d0fc7dd681ea11d91ede37857561b30b4.py for additional imports.\n",
            "INFO:filelock:Lock 140692544740264 acquired on /root/.cache/huggingface/datasets/ee5b3a098be9a0d5be9e705b2abdaf1c7bf81ebf279e965db8dbd7db418efa32.f1fd3484ce65950de4cdde6c3e2f332d0fc7dd681ea11d91ede37857561b30b4.py.lock\n",
            "INFO:nlp.load:Creating main folder for metric https://s3.amazonaws.com/datasets.huggingface.co/nlp/metrics/glue/glue.py at /usr/local/lib/python3.6/dist-packages/nlp/metrics/glue\n",
            "INFO:nlp.load:Creating specific version folder for metric https://s3.amazonaws.com/datasets.huggingface.co/nlp/metrics/glue/glue.py at /usr/local/lib/python3.6/dist-packages/nlp/metrics/glue/8e05e2fd41da255e1d729512a956f95cd909869a50ab5c8ac5ff2a060fbd2c68\n",
            "INFO:nlp.load:Copying script file from https://s3.amazonaws.com/datasets.huggingface.co/nlp/metrics/glue/glue.py to /usr/local/lib/python3.6/dist-packages/nlp/metrics/glue/8e05e2fd41da255e1d729512a956f95cd909869a50ab5c8ac5ff2a060fbd2c68/glue.py\n",
            "INFO:nlp.load:Couldn't find dataset infos file at https://s3.amazonaws.com/datasets.huggingface.co/nlp/metrics/glue/dataset_infos.json\n",
            "INFO:nlp.load:Creating metadata file for metric https://s3.amazonaws.com/datasets.huggingface.co/nlp/metrics/glue/glue.py at /usr/local/lib/python3.6/dist-packages/nlp/metrics/glue/8e05e2fd41da255e1d729512a956f95cd909869a50ab5c8ac5ff2a060fbd2c68/glue.json\n",
            "INFO:filelock:Lock 140692544740264 released on /root/.cache/huggingface/datasets/ee5b3a098be9a0d5be9e705b2abdaf1c7bf81ebf279e965db8dbd7db418efa32.f1fd3484ce65950de4cdde6c3e2f332d0fc7dd681ea11d91ede37857561b30b4.py.lock\n",
            "INFO:filelock:Lock 140692534348880 acquired on /root/.cache/huggingface/metrics/glue/1.0.0/cache-glue-0.arrow.lock\n",
            "INFO:nlp.arrow_writer:Done writing 277 examples in 4432 bytes /root/.cache/huggingface/metrics/glue/1.0.0/cache-glue-0.arrow.\n",
            "INFO:filelock:Lock 140692534348880 released on /root/.cache/huggingface/metrics/glue/1.0.0/cache-glue-0.arrow.lock\n",
            "INFO:filelock:Lock 140692534347872 acquired on /root/.cache/huggingface/metrics/glue/1.0.0/cache-glue-0.arrow.lock\n",
            "INFO:filelock:Lock 140692534347872 released on /root/.cache/huggingface/metrics/glue/1.0.0/cache-glue-0.arrow.lock\n",
            "INFO:nlp.arrow_dataset:Set __getitem__(key) output type to numpy for no columns  (when key is int or slice) and don't output other (un-formated) columns.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7256317689530686}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYAqVC6OJuPX",
        "outputId": "d8c805f9-fc79-4334-bc8a-0745b607b811",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evalute STS-B\n",
        "nlp.load_metric('glue', name=\"stsb\").compute(\n",
        "    preds_dict[\"stsb\"].predictions.flatten(),\n",
        "    preds_dict[\"stsb\"].label_ids,\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:nlp.load:Checking /root/.cache/huggingface/datasets/ee5b3a098be9a0d5be9e705b2abdaf1c7bf81ebf279e965db8dbd7db418efa32.f1fd3484ce65950de4cdde6c3e2f332d0fc7dd681ea11d91ede37857561b30b4.py for additional imports.\n",
            "INFO:filelock:Lock 140692534348656 acquired on /root/.cache/huggingface/datasets/ee5b3a098be9a0d5be9e705b2abdaf1c7bf81ebf279e965db8dbd7db418efa32.f1fd3484ce65950de4cdde6c3e2f332d0fc7dd681ea11d91ede37857561b30b4.py.lock\n",
            "INFO:nlp.load:Found main folder for metric https://s3.amazonaws.com/datasets.huggingface.co/nlp/metrics/glue/glue.py at /usr/local/lib/python3.6/dist-packages/nlp/metrics/glue\n",
            "INFO:nlp.load:Found specific version folder for metric https://s3.amazonaws.com/datasets.huggingface.co/nlp/metrics/glue/glue.py at /usr/local/lib/python3.6/dist-packages/nlp/metrics/glue/8e05e2fd41da255e1d729512a956f95cd909869a50ab5c8ac5ff2a060fbd2c68\n",
            "INFO:nlp.load:Found script file from https://s3.amazonaws.com/datasets.huggingface.co/nlp/metrics/glue/glue.py to /usr/local/lib/python3.6/dist-packages/nlp/metrics/glue/8e05e2fd41da255e1d729512a956f95cd909869a50ab5c8ac5ff2a060fbd2c68/glue.py\n",
            "INFO:nlp.load:Couldn't find dataset infos file at https://s3.amazonaws.com/datasets.huggingface.co/nlp/metrics/glue/dataset_infos.json\n",
            "INFO:nlp.load:Found metadata file for metric https://s3.amazonaws.com/datasets.huggingface.co/nlp/metrics/glue/glue.py at /usr/local/lib/python3.6/dist-packages/nlp/metrics/glue/8e05e2fd41da255e1d729512a956f95cd909869a50ab5c8ac5ff2a060fbd2c68/glue.json\n",
            "INFO:filelock:Lock 140692534348656 released on /root/.cache/huggingface/datasets/ee5b3a098be9a0d5be9e705b2abdaf1c7bf81ebf279e965db8dbd7db418efa32.f1fd3484ce65950de4cdde6c3e2f332d0fc7dd681ea11d91ede37857561b30b4.py.lock\n",
            "INFO:filelock:Lock 140692534348096 acquired on /root/.cache/huggingface/metrics/glue/1.0.0/cache-glue-0.arrow.lock\n",
            "INFO:nlp.arrow_writer:Done writing 1500 examples in 12000 bytes /root/.cache/huggingface/metrics/glue/1.0.0/cache-glue-0.arrow.\n",
            "INFO:filelock:Lock 140692534348096 released on /root/.cache/huggingface/metrics/glue/1.0.0/cache-glue-0.arrow.lock\n",
            "INFO:filelock:Lock 140692544738752 acquired on /root/.cache/huggingface/metrics/glue/1.0.0/cache-glue-0.arrow.lock\n",
            "INFO:filelock:Lock 140692544738752 released on /root/.cache/huggingface/metrics/glue/1.0.0/cache-glue-0.arrow.lock\n",
            "INFO:nlp.arrow_dataset:Set __getitem__(key) output type to numpy for no columns  (when key is int or slice) and don't output other (un-formated) columns.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pearson': 0.8976846151545946, 'spearmanr': 0.8965591143693535}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWKTZxcjFPnS",
        "outputId": "d1bccd8d-d8e7-4698-d94a-2330d1afb20b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evalute Commonsense QA\n",
        "np.mean(\n",
        "    np.argmax(preds_dict[\"commonsense_qa\"].predictions, axis=1)\n",
        "    == preds_dict[\"commonsense_qa\"].label_ids\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6240786240786241"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lxh5vgHor47-"
      },
      "source": [
        "You should expect scores of approximately:\n",
        "\n",
        "* RTE: ~0.74\n",
        "* STS-B: ~0.89/0.89\n",
        "* Commonsense QA: ~0.60\n"
      ]
    }
  ]
}